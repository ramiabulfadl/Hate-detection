{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Hate_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewtrWoRVQquH"
      },
      "source": [
        "\n",
        "\n",
        "# Hate Detection: BERT\n",
        "\n",
        "## Author: Rami Abulfadl\n",
        "\n",
        "The BERT model is fine tuned for binray classifier for hate detection using the dataset [Twitter hate speech] which can be downloaded from Kaggle´s competition with this link(https://www.kaggle.com/vkrahul/twitter-hate-speech?select=train_E6oV3lV.csv) in which tweets are identified as hateful by internet users and compiled by Hatebase.org based on Davidson et al. (https://arxiv.org/pdf/1703.04009.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL3cA0vRQquJ"
      },
      "source": [
        "### Load the required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3i4OtaOSSzX"
      },
      "source": [
        "# We will use the official tokenization script created by the Google team\n",
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUai2EiSnCQ",
        "outputId": "8302c20c-2c36-4f99-c588-7ce164209a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xtjt9vFSSzs"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_hub as hub\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "import keras\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tokenization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-V-G_IXjYVL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FOJrSKc5kwN",
        "outputId": "a4fb575f-0b33-45cf-a862-834bc34e6e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAazwd7rSS0k"
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/My Drive/TFMColab/hate/train.csv\")\n",
        "val = pd.read_csv(\"/content/drive/My Drive/TFMColab/hate/dev.csv\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/TFMColab/hate/test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4X7fcjvSSz-"
      },
      "source": [
        "### Define Helper Functions\n",
        "[Source](https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub) of helper functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUeYQc5vSS0A"
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=160):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dREk4XJzSS0M"
      },
      "source": [
        "def build_model(bert_layer, max_len=160):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    out = Dense(1, activation='sigmoid')(clf_output)\n",
        "    \n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy',keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.TruePositives()])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhYaMiS8SS0X"
      },
      "source": [
        "### Load BERT from the Tensorflow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNMSjzwASS0Z",
        "outputId": "2d108e38-e69d-4b5f-a7e5-753ed9a46076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.5 s, sys: 1.85 s, total: 12.4 s\n",
            "Wall time: 12.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNDCq_z-Qqut"
      },
      "source": [
        "### Load CSV files containing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TMjuMjOQqux"
      },
      "source": [
        "### Load tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVMoBrN_SS1A"
      },
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xekR2ewQQqu1"
      },
      "source": [
        "### Text encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKprUPE_SS1I"
      },
      "source": [
        "train_input = bert_encode(train.Phrase.values, tokenizer, max_len = 160)\n",
        "test_input = bert_encode(test.Phrase.values, tokenizer, max_len = 160)\n",
        "val_input = bert_encode(val.Phrase.values, tokenizer, max_len = 160)\n",
        "\n",
        "\n",
        "\n",
        "train_labels = train.sentiment_values.values\n",
        "test_labels = test.sentiment_values.values\n",
        "val_labels = val.sentiment_values.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIVuBBuaSS1R"
      },
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-5pXP86SS1T",
        "outputId": "20f943ae-1b60-456c-cfcb-6aef82ddd4e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "model = build_model(bert_layer, max_len = 160)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_1 (KerasLayer)      [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 1024)]       0           keras_layer_1[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            1025        tf_op_layer_strided_slice[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 335,142,914\n",
            "Trainable params: 335,142,913\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWPVFHsXQqu_"
      },
      "source": [
        "### Save the best model and early stopping\n",
        "\n",
        "To prevent the model from overfitting early stopping has been enabled.\n",
        "\n",
        "Early stopping is a method that allows us to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out/validation dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mj-xJTW8h_N",
        "outputId": "dd764a15-90db-4884-f02b-8776a43b26d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Save the model after every epoch.\n",
        "saveBestModel = ModelCheckpoint('/content/drive/My Drive/TFMColab/hate/best_model.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "# Stop training when a monitored quantity has stopped improving.\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD119wupQqvK"
      },
      "source": [
        "### Fit the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtDjzJ_PSS1c",
        "outputId": "2371a5a9-6d0a-48bf-b7aa-908bd85d9a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "train_history = model.fit(\n",
        "    train_input, train_labels,\n",
        "    validation_data=(val_input, val_labels),\n",
        "    epochs=7,\n",
        "    batch_size=14,\n",
        "    callbacks=[saveBestModel, earlyStopping]\n",
        ")\n",
        "\n",
        "#model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "1824/1824 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9516 - precision: 0.7543 - recall: 0.4618 - true_positives: 829.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1824/1824 [==============================] - 2769s 2s/step - loss: 0.1347 - accuracy: 0.9516 - precision: 0.7543 - recall: 0.4618 - true_positives: 829.0000 - val_loss: 0.1044 - val_accuracy: 0.9613 - val_precision: 0.7751 - val_recall: 0.6009 - val_true_positives: 131.0000\n",
            "Epoch 2/7\n",
            "1824/1824 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9764 - precision: 0.8916 - recall: 0.7560 - true_positives: 1357.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1824/1824 [==============================] - 2768s 2s/step - loss: 0.0668 - accuracy: 0.9764 - precision: 0.8916 - recall: 0.7560 - true_positives: 1357.0000 - val_loss: 0.1053 - val_accuracy: 0.9656 - val_precision: 0.8497 - val_recall: 0.5963 - val_true_positives: 130.0000\n",
            "Epoch 3/7\n",
            "1824/1824 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9930 - precision: 0.9681 - recall: 0.9309 - true_positives: 1671.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1824/1824 [==============================] - 2769s 2s/step - loss: 0.0225 - accuracy: 0.9930 - precision: 0.9681 - recall: 0.9309 - true_positives: 1671.0000 - val_loss: 0.1462 - val_accuracy: 0.9622 - val_precision: 0.8750 - val_recall: 0.5138 - val_true_positives: 112.0000\n",
            "Epoch 4/7\n",
            "1824/1824 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989 - precision: 0.9950 - recall: 0.9900 - true_positives: 1777.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1824/1824 [==============================] - 2768s 2s/step - loss: 0.0040 - accuracy: 0.9989 - precision: 0.9950 - recall: 0.9900 - true_positives: 1777.0000 - val_loss: 0.1491 - val_accuracy: 0.9631 - val_precision: 0.7676 - val_recall: 0.6514 - val_true_positives: 142.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdsWL-x59ia2"
      },
      "source": [
        "### Evaluate model results with test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNvGubBAd15h"
      },
      "source": [
        "Results were obtained by using the 'predict' function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILZy1TbvSS1m"
      },
      "source": [
        "test_pred = model.predict(test_input)\n",
        "test_pred = test_pred.round().astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4ZQXjErdbJ6"
      },
      "source": [
        "recall = metrics.recall_score(test_labels,test_pred)\n",
        "precision = metrics.precision_score(test_labels,test_pred)\n",
        "f1_score = metrics.f1_score(test_labels,test_pred)\n",
        "accuracy = metrics.accuracy_score(test_labels,test_pred)\n",
        "loss = metrics.log_loss(test_labels,test_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfNM2QziiTg3",
        "outputId": "0f08a0a0-40ed-451e-c140-7ebcf6505474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print('Loss:',loss)\n",
        "print('Accuracy:',accuracy)\n",
        "print('Precision:',precision)\n",
        "print('Recall:',recall)\n",
        "print('f1 score:',f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 1.2077359158654162\n",
            "Accuracy: 0.9650327817670934\n",
            "Precision: 0.7853658536585366\n",
            "Recall: 0.7030567685589519\n",
            "f1 score: 0.7419354838709677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmeczjWXeCvo",
        "outputId": "4b63ab28-7bd2-4373-89f0-af7b7fbeb1eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# kappa\n",
        "kappa = cohen_kappa_score(test_labels,test_pred)\n",
        "print('Cohens kappa: %f' % kappa)\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(test_labels,test_pred)\n",
        "print('ROC AUC: %f' % auc)\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(test_labels,test_pred)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cohens kappa: 0.723243\n",
            "ROC AUC: 0.844131\n",
            "[[2930   44]\n",
            " [  68  161]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80sBVHbPiaSv"
      },
      "source": [
        "### Extract False Positives and False Negatives\n",
        "\n",
        "False Positives and False Negatives are stored in a CSV file for posterior analysis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoQs0Yd2ibf5"
      },
      "source": [
        "def getFP_FN_lists(test_X, test_y, pred_y):\n",
        "    FP_text = []\n",
        "    FP_index = []\n",
        "    FN_text = []\n",
        "    FN_index = []\n",
        "    for i in range(len(test_y)):\n",
        "        if(pred_y[i]==1 and test_y[test_y.index[i]]==0):\n",
        "            FP_text.append(test['Phrase'][test_y.index[i]])\n",
        "            FP_index.append(test_y.index[i])\n",
        "        elif(pred_y[i]==0 and test_y[test_y.index[i]]==1):\n",
        "            FN_text.append(test['Phrase'][test_y.index[i]])\n",
        "            FN_index.append(test_y.index[i])\n",
        "            \n",
        "    return FP_text,FP_index,FN_text,FN_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi9mx_hHj6UN"
      },
      "source": [
        "'''Returns 2 dataframes, one with all the False Positives and one with all the False Negatives'''\n",
        "def getFP_FN(test_X, test_y, pred_y):\n",
        "    FP_text,FP_index,FN_text,FN_index = getFP_FN_lists(test_X, test_y, pred_y)\n",
        "    d_FP = {'FP_text':FP_text,'FP_index':FP_index}\n",
        "    df_FP = pd.DataFrame(d_FP)\n",
        "    d_FN = {'FN_text':FN_text,'FN_index':FN_index}\n",
        "    df_FN = pd.DataFrame(d_FN)\n",
        "    \n",
        "    return df_FP,df_FN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTyuTkRMlW1d"
      },
      "source": [
        "# We get the FPs and FNs as DataFrames and store them to CSVs\n",
        "df_FP,df_FN = getFP_FN(test['Phrase'], test['sentiment_values'],test_pred)\n",
        "df_FP.to_csv('/content/drive/My Drive/TFMColab/hate/bert_FP_bert.csv', index=True)\n",
        "df_FN.to_csv('/content/drive/My Drive/TFMColab/hate/bert_FN_bert.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}