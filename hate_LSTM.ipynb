{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hate_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "notify_time": "5",
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "510.85px",
        "left": "1550px",
        "right": "20px",
        "top": "120px",
        "width": "350px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XqvvBLQkx3-q"
      },
      "source": [
        "# Hate Detection: LSTM\n",
        "\n",
        "## Author: Rami Abulfadl\n",
        "\n",
        "A Bi-LSTM network is created as binray classifier for hate detection using the dataset [Twitter hate speech] which can be downloaded from KaggleÂ´s competition with this link(https://www.kaggle.com/vkrahul/twitter-hate-speech?select=train_E6oV3lV.csv) in which tweets are identified as hateful by internet users and compiled by Hatebase.org based on Davidson et al. (https://arxiv.org/pdf/1703.04009.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G7yHquTOx3-r"
      },
      "source": [
        "###  **1. Importation**\n",
        "The necessary librraies needed to create the model and the dataset it self have been imported in this section\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_ahkojuzHIg",
        "colab_type": "text"
      },
      "source": [
        "**1.1** Importing necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-10T08:38:45.362099Z",
          "start_time": "2020-05-10T08:38:41.921456Z"
        },
        "colab_type": "code",
        "id": "upfST-E3x3-t",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import tensorflow as tf\n",
        "from keras.layers import LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model, Sequential\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gIyMIwvVx3-3"
      },
      "source": [
        "\n",
        "\n",
        "**1.2.** Importing the CSV files of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qOpyIc-fymIH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87a3d3cf-0648-435a-adad-5c7d8df44136"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-10T08:38:45.544234Z",
          "start_time": "2020-05-10T08:38:45.443796Z"
        },
        "colab_type": "code",
        "id": "-RuMjGnAx3-4",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/My Drive/TFMColab/hate/train.csv\")\n",
        "val = pd.read_csv(\"/content/drive/My Drive/TFMColab/hate/dev.csv\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/TFMColab/hate/test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V9KhphwGx3-_"
      },
      "source": [
        "###  **2. Preprocessing**\n",
        "\n",
        "Typically, the tokenizer provided by Keras has been set to vectorize the tweets into integers by fitting it on the training tweets. Most frequenct words are kept up to 10000 words. Texts are not converted into lower case as it may add information forexample when a user is shouting. \n",
        "\n",
        "All punctuation, plus tabs and line breaks are filtered from the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-10T08:38:47.348652Z",
          "start_time": "2020-05-10T08:38:45.724660Z"
        },
        "colab_type": "code",
        "id": "vyi3UEMhx3-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "504b5407-3361-4bed-ab1a-cdaf94380d92"
      },
      "source": [
        "max_words = 10000 \n",
        "maxlen = 25 \n",
        "embedding_dim = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words,lower=False, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "\n",
        "#tokenizer fitting on training tweets\n",
        "tokenizer.fit_on_texts(list(train['Phrase']))\n",
        "word_index = tokenizer.word_index\n",
        "print('There are %s unique tokens.' % len(word_index))\n",
        "\n",
        "#apply the tokenizer on the 3 datasets partitions\n",
        "train_X = tokenizer.texts_to_sequences(train['Phrase'])\n",
        "test_X = tokenizer.texts_to_sequences(test['Phrase'])\n",
        "val_X = tokenizer.texts_to_sequences(val['Phrase'])\n",
        "\n",
        "#Reshape the outcome into a numpy array\n",
        "train_X = pad_sequences(train_X, maxlen = maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen = maxlen)\n",
        "val_X = pad_sequences(val_X, maxlen = maxlen)\n",
        "\n",
        "train_y = train['sentiment_values']\n",
        "test_y = test['sentiment_values']\n",
        "val_y = val['sentiment_values']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 39745 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6hPtF0iO1Yb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7e0c58a-e33a-4c9b-e19c-d3fdc6fbe817"
      },
      "source": [
        "train_X.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25533, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aPffAJDIx3_E"
      },
      "source": [
        "Glove embedding file has been uploaded, which is coposed of pre-trained word vectors glove.6B.100d that contains 6 B tokens of 400 k vocab forming a 100 dimension vector representation gathered form Wikipedia 2014 and Gigaword 5 corpora. The embedding matrix is then prepaired before being used as a manual for the embedding layer in Bi-LSTM model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-10T08:39:30.132017Z",
          "start_time": "2020-05-10T08:38:47.536800Z"
        },
        "colab_type": "code",
        "id": "Y9tT0SZbx3_G",
        "colab": {}
      },
      "source": [
        "#defining glove directory \n",
        "EMBEDDING_FILE = '/content/drive/My Drive/TFMColab/glove_6B_100d.txt'\n",
        "\n",
        "def coefs_fetcher(word,*arr): \n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "#construct the embedding index from the glove file\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(EMBEDDING_FILE, encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "        word, coefs = coefs_fetcher(*line.split(\" \"))\n",
        "        embeddings_index[word] = coefs\n",
        "            \n",
        "# embedding matrix \n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: \n",
        "        # words not in the embedding index are regarded as zeros\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3LZe5Ntpx3_K"
      },
      "source": [
        "### **3. Build LSTM Model**\n",
        "\n",
        "The model layers are constructed by an 128 unit Bi-LSTM layer after the embedding layer. Then, the input is designed to pass through 2 hidden layers with relu activation functions, consisting of 40 and 20 units respectively.Lastley final probability is given by the output layer with a sigmoid activation function for binary classification either 1 for hatefull tweet or 0 for neutral."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-10T08:48:19.482797Z",
          "start_time": "2020-05-10T08:38:46.714Z"
        },
        "colab_type": "code",
        "id": "ykFP7yQcx3_L",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, embedding_dim, weights = [embedding_matrix]))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(40, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(20, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.TruePositives()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ysvBfLhAx3_Q"
      },
      "source": [
        "For regularization purpose, the dropout with p=0.5 is set in the above section. Moreover, early stopping approach is set through comapring the loss of the validation and training partitions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-10T08:48:19.494511Z",
          "start_time": "2020-05-10T08:38:58.047Z"
        },
        "colab_type": "code",
        "id": "kP9f8-oNx3_R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "187eaae9-fa72-4c57-f35e-1c6282aac1cc"
      },
      "source": [
        "#Autosave after each epochs\n",
        "saveBestModel = keras.callbacks.ModelCheckpoint('/content/drive/My Drive/TFMColab/best_model.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "#setting early stoping with patience of 2 epochs\n",
        "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOyjvTJ5vKCt",
        "colab_type": "text"
      },
      "source": [
        "### **4. Fit the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ciwd1MTUNAvY",
        "colab_type": "text"
      },
      "source": [
        "The class weights had been adjusted in order to deal with the imbalance of classes before fitting the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DePKu3MZx3_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "55111d46-d9d7-4b46-b9e5-1ffeb94581f6"
      },
      "source": [
        "class_weight = {0: 1.,\n",
        "                1: 10.\n",
        "                }\n",
        "batch_size = 100\n",
        "epochs = 25\n",
        "model.fit(train_X, train_y, batch_size=batch_size,class_weight=class_weight, epochs=epochs, validation_data=(val_X, val_y), callbacks=[saveBestModel, earlyStopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "256/256 [==============================] - ETA: 0s - loss: 0.7845 - accuracy: 0.8001 - precision_1: 0.2229 - recall_1: 0.7409 - true_positives_1: 1330.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "256/256 [==============================] - 12s 49ms/step - loss: 0.7845 - accuracy: 0.8001 - precision_1: 0.2229 - recall_1: 0.7409 - true_positives_1: 1330.0000 - val_loss: 0.1737 - val_accuracy: 0.9383 - val_precision_1: 0.5385 - val_recall_1: 0.6101 - val_true_positives_1: 133.0000\n",
            "Epoch 2/25\n",
            "255/256 [============================>.] - ETA: 0s - loss: 0.4634 - accuracy: 0.9001 - precision_1: 0.4040 - recall_1: 0.8857 - true_positives_1: 1588.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "256/256 [==============================] - 12s 46ms/step - loss: 0.4631 - accuracy: 0.9002 - precision_1: 0.4042 - recall_1: 0.8858 - true_positives_1: 1590.0000 - val_loss: 0.1667 - val_accuracy: 0.9402 - val_precision_1: 0.5415 - val_recall_1: 0.7477 - val_true_positives_1: 163.0000\n",
            "Epoch 3/25\n",
            "255/256 [============================>.] - ETA: 0s - loss: 0.3319 - accuracy: 0.9343 - precision_1: 0.5180 - recall_1: 0.9251 - true_positives_1: 1656.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "256/256 [==============================] - 12s 46ms/step - loss: 0.3320 - accuracy: 0.9343 - precision_1: 0.5183 - recall_1: 0.9253 - true_positives_1: 1661.0000 - val_loss: 0.1639 - val_accuracy: 0.9355 - val_precision_1: 0.5146 - val_recall_1: 0.8073 - val_true_positives_1: 176.0000\n",
            "Epoch 4/25\n",
            "256/256 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.9550 - precision_1: 0.6158 - recall_1: 0.9554 - true_positives_1: 1715.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "256/256 [==============================] - 12s 46ms/step - loss: 0.2200 - accuracy: 0.9550 - precision_1: 0.6158 - recall_1: 0.9554 - true_positives_1: 1715.0000 - val_loss: 0.1634 - val_accuracy: 0.9408 - val_precision_1: 0.5437 - val_recall_1: 0.7706 - val_true_positives_1: 168.0000\n",
            "Epoch 5/25\n",
            "256/256 [==============================] - ETA: 0s - loss: 0.1667 - accuracy: 0.9636 - precision_1: 0.6653 - recall_1: 0.9710 - true_positives_1: 1743.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "256/256 [==============================] - 12s 47ms/step - loss: 0.1667 - accuracy: 0.9636 - precision_1: 0.6653 - recall_1: 0.9710 - true_positives_1: 1743.0000 - val_loss: 0.1859 - val_accuracy: 0.9352 - val_precision_1: 0.5134 - val_recall_1: 0.7936 - val_true_positives_1: 173.0000\n",
            "Epoch 6/25\n",
            "256/256 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9724 - precision_1: 0.7248 - recall_1: 0.9799 - true_positives_1: 1759.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "256/256 [==============================] - 12s 47ms/step - loss: 0.1295 - accuracy: 0.9724 - precision_1: 0.7248 - recall_1: 0.9799 - true_positives_1: 1759.0000 - val_loss: 0.1952 - val_accuracy: 0.9464 - val_precision_1: 0.5768 - val_recall_1: 0.7752 - val_true_positives_1: 169.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9aff47be80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mWBKsDHBx3_Y"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Moc3Pr8Ox3_Z"
      },
      "source": [
        "\n",
        "### **5. Evaluate model results with test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4k9Dap4Ix3_a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "982fc3de-9932-4a8e-8a0b-b52e5fef515a"
      },
      "source": [
        "loss, accuracy, precision, recall, true_positives = model.evaluate(test_X, test_y, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2464 - accuracy: 0.9363 - precision_1: 0.5407 - recall_1: 0.7249 - true_positives_1: 166.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iFLlzmcdx3_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4acf2ffa-fdb0-494f-aaad-8f2ff5419297"
      },
      "source": [
        "#calculating the F1 score\n",
        "mult=precision*recall\n",
        "sum=precision+recall\n",
        "frac=mult/sum\n",
        "f1_score=2*frac\n",
        "\n",
        "#the evaluation metrics\n",
        "print('The Accuracy is:',accuracy)\n",
        "print('The f1 score is:',f1_score)\n",
        "print('The Precision is:',precision)\n",
        "print('The Recall is:',recall)\n",
        "print('The Loss is:',loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Accuracy is: 0.9363096952438354\n",
            "The f1 score is: 0.6194029688361286\n",
            "The Precision is: 0.5407165884971619\n",
            "The Recall is: 0.7248908281326294\n",
            "The Loss is: 0.24641041457653046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "udKLHyRYx3_r"
      },
      "source": [
        "### **6. Extract False Positives and False Negatives**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRb5yr30pIF1",
        "colab_type": "text"
      },
      "source": [
        "The saved model predicts the sentiment of the test partition inorder to compare them with the actual tweet labels.Then the confusion matrix is constructed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-K04N8gmx3_s",
        "colab": {}
      },
      "source": [
        "predict_y = model.predict_classes(test_X, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MeXIJd2Jx3_w",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "aa86674a-f44c-4387-9708-f77f0ffee6e0"
      },
      "source": [
        "confusion_matrix(test_y, predict_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2833,  141],\n",
              "       [  63,  166]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kY1Z798ix3_0"
      },
      "source": [
        "The following function is created to panda dataframes for the false positives and negatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JLK96ycjx3_1",
        "colab": {}
      },
      "source": [
        "def getFP_FN(test_X, test_y, pred_y):\n",
        "    FP_text = []\n",
        "    FP_index = []\n",
        "    FN_text = []\n",
        "    FN_index = []\n",
        "    for i in range(len(test_y)):\n",
        "        if(pred_y[i]==1 and test_y[test_y.index[i]]==0):\n",
        "            FP_text.append(test['Phrase'][test_y.index[i]])\n",
        "            FP_index.append(test_y.index[i])\n",
        "        elif(pred_y[i]==0 and test_y[test_y.index[i]]==1):\n",
        "            FN_text.append(test['Phrase'][test_y.index[i]])\n",
        "            FN_index.append(test_y.index[i])\n",
        "    d_FP = {'FP_text':FP_text,'FP_index':FP_index}\n",
        "    df_FP = pd.DataFrame(d_FP)\n",
        "    d_FN = {'FN_text':FN_text,'FN_index':FN_index}\n",
        "    df_FN = pd.DataFrame(d_FN)\n",
        "            \n",
        "    return df_FP,df_FN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EHh9434Ex3_9",
        "colab": {}
      },
      "source": [
        "#directory of saved CSV files of false positives and negatives\n",
        "df_FP,df_FN = getFP_FN(test_X, test_y, predict_y)\n",
        "df_FP.to_csv('/content/drive/My Drive/TFMColab/hate/hateFP.csv', index=True)\n",
        "df_FN.to_csv('/content/drive/My Drive/TFMColab/hate/hateFN.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt7rqs0B42d8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "3812a393-e970-4645-b784-a4c84f208b09"
      },
      "source": [
        "df_FP"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FP_text</th>\n",
              "      <th>FP_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#stupidity makes me more   than even #negligen...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it's a firework!! weeheeeee~ Ã°ÂÂÂÃ°ÂÂÂÃ°ÂÂÂÃ°ÂÂÂÃ°...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user but it's your fault you have to use it t...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sick verbal irony of the #left:  equaling homo...</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user , shocked by your ignorance</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>@user when a former liberal warrior becomes a...</td>\n",
              "      <td>3099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>cue the violins   #sososad</td>\n",
              "      <td>3103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>#whatson  @user @user @user @user @user please...</td>\n",
              "      <td>3162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>@user .. #new#year..</td>\n",
              "      <td>3171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>#jalandhar @user says   not appointing honest ...</td>\n",
              "      <td>3177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>141 rows Ã 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               FP_text  FP_index\n",
              "0    #stupidity makes me more   than even #negligen...         8\n",
              "1    it's a firework!! weeheeeee~ Ã°ÂÂÂÃ°ÂÂÂÃ°ÂÂÂÃ°ÂÂÂÃ°...        19\n",
              "2    @user but it's your fault you have to use it t...        28\n",
              "3    sick verbal irony of the #left:  equaling homo...        99\n",
              "4                  @user , shocked by your ignorance         148\n",
              "..                                                 ...       ...\n",
              "136   @user when a former liberal warrior becomes a...      3099\n",
              "137                        cue the violins   #sososad       3103\n",
              "138  #whatson  @user @user @user @user @user please...      3162\n",
              "139                              @user .. #new#year..       3171\n",
              "140  #jalandhar @user says   not appointing honest ...      3177\n",
              "\n",
              "[141 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLNSXgWm5Tq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "56538896-a38b-447a-80d4-3f5c992a6e02"
      },
      "source": [
        "df_FN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FN_text</th>\n",
              "      <th>FN_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fox new just coming out and saying it bluntly....</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user thank you!! the power of #social #media!...</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>decolonizing the curriculum: the only way thro...</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yay! except #ellen made  comments so should we...</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>show me your tits, idiot!</td>\n",
              "      <td>205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>in queue with basket of food shopping, 50's gu...</td>\n",
              "      <td>2925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>@user i have the ssn,address,home network info...</td>\n",
              "      <td>2933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>why? please explain to us why we're, \"bad.\"</td>\n",
              "      <td>3006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>goodbye 2016.... i definitely hope we leave be...</td>\n",
              "      <td>3133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>@user 'an unappetizing scam' :-) | women, we n...</td>\n",
              "      <td>3188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows Ã 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              FN_text  FN_index\n",
              "0   fox new just coming out and saying it bluntly....        47\n",
              "1   @user thank you!! the power of #social #media!...        63\n",
              "2   decolonizing the curriculum: the only way thro...       113\n",
              "3   yay! except #ellen made  comments so should we...       125\n",
              "4                          show me your tits, idiot!        205\n",
              "..                                                ...       ...\n",
              "58  in queue with basket of food shopping, 50's gu...      2925\n",
              "59  @user i have the ssn,address,home network info...      2933\n",
              "60      why? please explain to us why we're, \"bad.\"        3006\n",
              "61  goodbye 2016.... i definitely hope we leave be...      3133\n",
              "62  @user 'an unappetizing scam' :-) | women, we n...      3188\n",
              "\n",
              "[63 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}